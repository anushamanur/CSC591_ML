{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from natsort import natsorted, ns\n",
    "import impyute as impy\n",
    "import math\n",
    "from statistics import mean \n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading groundtruth file\n",
    "file_name = r\"C:\\Users\\kshah3\\Documents\\Kartik IMP\\CSC591 ML\\Ap1\\AP1 Materials and Files-20190829\\train_data\\train_data\\train_groundtruth\\{}.csv\"\n",
    "df_list = []\n",
    "for i in range(1, 6001):\n",
    "    pt=pd.read_csv(file_name.format(i))\n",
    "    pt['pt_no'] = i\n",
    "    pt['index'] = range(1,len(pt)+1)\n",
    "    df_list.append(pt)\n",
    "df_truth = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean imputation\n",
    "def impute_simple_mean(df_train_column):\n",
    "    df_train_column = df_train_column.fillna(df_train_column.mean())\n",
    "    return df_train_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bfill imputation\n",
    "def impute_bfill(df_train_column):\n",
    "    if(math.isnan(df_train_column.loc[len(df_train_column)-1]) == True ):\n",
    "        if(math.isnan(df_train_column.loc[len(df_train_column)-2]) == True ):\n",
    "            if(math.isnan(df_train_column.loc[len(df_train_column)-3]) == True ):\n",
    "                if(math.isnan(df_train_column.loc[len(df_train_column)-4]) == True ):\n",
    "                    if(math.isnan(df_train_column.loc[len(df_train_column)-5]) == True ):\n",
    "                        if(math.isnan(df_train_column.loc[len(df_train_column)-6]) == True ):\n",
    "                            df_train_column.loc[len(df_train_column)-6] = df_train_column.loc[len(df_train_column)-7]\n",
    "                        df_train_column.loc[len(df_train_column)-5] = df_train_column.loc[len(df_train_column)-6]    \n",
    "                    df_train_column.loc[len(df_train_column)-4] = df_train_column.loc[len(df_train_column)-5]\n",
    "                df_train_column.loc[len(df_train_column)-3] = df_train_column.loc[len(df_train_column)-4]     \n",
    "            df_train_column.loc[len(df_train_column)-2] = df_train_column.loc[len(df_train_column)-3]\n",
    "        df_train_column.loc[len(df_train_column)-1] = df_train_column.loc[len(df_train_column)-2]\n",
    "    df_train_column = df_train_column.fillna(df_train_column.bfill())\n",
    "    if(df_train_column.isnull().sum()>0):\n",
    "        print(df_train_column)\n",
    "    return df_train_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kartik mean 4 imputation\n",
    "def impute_fourmean(df_train_column):\n",
    "    column_datas = []\n",
    "    column_datas = list(df_train_column)\n",
    "    empty = []\n",
    "    elements = []\n",
    "    final_elements = []\n",
    "    idx = 0\n",
    "    count = 0\n",
    "    for column_data in column_datas:\n",
    "        elements.append(column_data)\n",
    "        if  math.isnan(column_data):\n",
    "            empty.append(idx)\n",
    "        if(count==3 and (len(empty)-1)<3):\n",
    "            if(empty!=[]):\n",
    "                for empty_index in empty:\n",
    "                    #print(\"K\")\n",
    "                    #print(empty_index)\n",
    "                    column_datas[empty_index] = np.nanmean(elements)\n",
    "            count = -1\n",
    "            elements = []\n",
    "            empty = []\n",
    "        if(count==3 and (len(empty))==4):\n",
    "            if(empty!=[]):\n",
    "                for empty_index in empty:\n",
    "                    #print(\"element\")\n",
    "                    #print(empty_index)\n",
    "                    column_datas[empty_index] = np.nanmean(column_datas)\n",
    "            count = -1\n",
    "            elements = []\n",
    "            empty = []       \n",
    "        if(count<3 and idx == len(column_datas)-1):\n",
    "            if(empty!=[]):\n",
    "                for empty_index in empty:\n",
    "                        last_elements = []\n",
    "                        last_elements.append(column_datas[idx])\n",
    "                        last_elements.append(column_datas[idx-1])\n",
    "                        last_elements.append(column_datas[idx-2])\n",
    "                        last_elements.append(column_datas[idx-3])\n",
    "                        #print(last_elements)\n",
    "                        column_datas[empty_index] = np.nanmean(last_elements)\n",
    "        final_elements.append(column_data)\n",
    "        idx+=1\n",
    "        count+=1\n",
    "#    cld = pd.DataFrame(column_datas)\n",
    "#     cld = cld.iloc[0:, 0]\n",
    "#     columns = ['Potassium']\n",
    "#     cld.columns=columns\n",
    "    return pd.Series(column_datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name_fourmean = r\"C:\\Users\\kshah3\\Documents\\Kartik IMP\\CSC591 ML\\Ap1\\AP1 Materials and Files-20190829\\train_data\\train_data\\train_with_fourmean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name_bfill = r\"C:\\Users\\kshah3\\Documents\\Kartik IMP\\CSC591 ML\\Ap1\\AP1 Materials and Files-20190829\\train_data\\train_data\\train_with_bfill\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading missing file and imputing it\n",
    "columns = ['time', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11', 'X12', 'X13']\n",
    "file_name = r\"C:\\Users\\kshah3\\Documents\\Kartik IMP\\CSC591 ML\\Ap1\\AP1 Materials and Files-20190829\\train_data\\train_data\\train_with_missing\\{}.csv\" # use your path\n",
    "df_list = []\n",
    "for i in range(1, 6001):\n",
    "    pt=pd.read_csv(file_name.format(i))\n",
    "    for index in range(pt.shape[1]):\n",
    "        # Select column by index position using iloc[]\n",
    "        columnSeriesObj = pt.iloc[: , index]\n",
    "        re = impute_fourmean(columnSeriesObj)\n",
    "        df_list.append(re.tolist())\n",
    "    df_train = pd.DataFrame(df_list).T\n",
    "    df_train.columns= columns\n",
    "    df_csv = df_train.to_csv(\"{}\\{}.csv\".format(dir_name_fourmean,i),mode = 'w', index=False)\n",
    "    df_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = df_train.to_csv('test.csv',mode = 'w', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading naidx file\n",
    "file_name =  r\"C:\\Users\\kshah3\\Documents\\Kartik IMP\\CSC591 ML\\Ap1\\AP1 Materials and Files-20190829\\train_data\\train_data\\naidx.csv\"\n",
    "df_naidx=pd.read_csv(file_name)\n",
    "len_naidx=len(df_naidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourmean = r\"C:\\Users\\kshah3\\Documents\\Kartik IMP\\CSC591 ML\\Ap1\\AP1 Materials and Files-20190829\\train_data\\train_data\\train_with_fourmean\\{}.csv\"\n",
    "df_list_mice = []\n",
    "for i in range(1, 6001):\n",
    "    pt=pd.read_csv(fourmean.format(i))\n",
    "    pt['pt_no'] = i\n",
    "    pt['index'] = range(1,len(pt)+1)\n",
    "    df_list_mice.append(pt)\n",
    "imputed_val = pd.concat(df_list_mice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23773964545755322, 0.2617864932491645, 0.24291340172067272, 0.2477396712018247, 0.2520984569446383, 0.25578316905419274, 0.27357313687687596, 0.21840169199273932, 0.2573485792251647, 0.23859827411428927, 0.21833243825388332, 0.24406369773142914, 0.2795095996498526]\n"
     ]
    }
   ],
   "source": [
    "#RMSD per column\n",
    "d=[-1]*13\n",
    "diff=0\n",
    "for i in range(1,14):\n",
    "    df_naidx_sub=df_naidx.loc[df_naidx['test'] == ('X'+str(i))]\n",
    "    len_naidx_per_col=len(df_naidx_sub)\n",
    "    diff=0\n",
    "    for index, row in df_naidx_sub.iterrows():\n",
    "        x= imputed_val.loc[(imputed_val['index'] == row['i']) & (imputed_val['pt_no'] == row['pt.num']) ,row['test']].iloc[0]\n",
    "        y= df_truth.loc[(df_truth['index'] == row['i']) & (df_truth['pt_no'] == row['pt.num']),row['test']].iloc[0]\n",
    "        df_truth_sub=df_truth.loc[(df_truth['pt_no'] == row['pt.num'])]\n",
    "        rnge=df_truth_sub[row['test']].max()-df_truth_sub[row['test']].min()\n",
    "        diff+=((x-y)/rnge)**2\n",
    "    d[i-1]=math.sqrt(diff/len_naidx_per_col)\n",
    "    \n",
    "print (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
