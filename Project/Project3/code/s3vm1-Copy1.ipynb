{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Jupyter notebook from frameworks.ipynb\n",
      "Importing Jupyter notebook from qns3vm.ipynb\n",
      "Importing Jupyter notebook from methods.ipynb\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn import metrics\n",
    "import pickle\n",
    "from nltk import word_tokenize\n",
    "from sklearn import linear_model, neural_network\n",
    "from sklearn.svm import SVC\n",
    "import timeit\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import nbimporter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from frameworks import SelfLearningModel, SKTSVM\n",
    "from methods import evaluate_and_plot\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 20 newsgroups dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18846"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove metadata \n",
    "remove = ('headers', 'footers', 'quotes') \n",
    "RANDOM_STATE = 10\n",
    "\n",
    "# Load dataset\n",
    "print(\"Loading 20 newsgroups dataset\")\n",
    "newsdata = fetch_20newsgroups(subset='all')\n",
    "len(newsdata.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [12928 11326  1229 ... 13255  6125  9583] TEST: [ 4781 14913  3401 ... 13848   318  9882]\n",
      "Data loaded\n",
      "\n",
      "Training data documents: 7161\n",
      "Development data documents: 7915\n",
      "Test data documents: 3770\n",
      "\n",
      "Total Newsgroups : ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "X_remaining, X_test, Y_remaining, Y_test = train_test_split(newsdata.data, newsdata.target, test_size=0.20, random_state=RANDOM_STATE)\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size= 0.525,random_state=RANDOM_STATE)\n",
    "X_remaining=np.array(X_remaining)\n",
    "Y_remaining=np.array(Y_remaining)\n",
    "for train_index, test_index in sss.split(X_remaining,Y_remaining):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_dev = X_remaining[train_index], X_remaining[test_index]\n",
    "    y_train, y_dev = Y_remaining[train_index], Y_remaining[test_index]\n",
    "    \n",
    "print('Data loaded')\n",
    "print()\n",
    "print('Training data documents:', len(X_train))\n",
    "print('Development data documents:', len(X_dev))\n",
    "print('Test data documents:', len(X_test))\n",
    "print()\n",
    "print('Total Newsgroups :', newsdata.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data\n",
      "Data saved!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (\"Saving data\")\n",
    "np.save('data/train_data.npy', X_train)\n",
    "np.save('data/dev_data.npy', X_dev)\n",
    "np.save('data/test_data.npy', X_test)\n",
    "\n",
    "np.save('data/train_label.npy', y_train)\n",
    "np.save('data/dev_label.npy', y_dev)\n",
    "np.save('data/test_label.npy', Y_test)\n",
    "\n",
    "print (\"Data saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15076L,) (15076L,) (15076L,)\n"
     ]
    }
   ],
   "source": [
    "y_minus=np.full(len(y_dev), -1, dtype=int)\n",
    "\n",
    "X_concat=np.concatenate((X_train, X_dev), axis=None)\n",
    "y_concat=np.concatenate((y_train, y_minus), axis=None)\n",
    "y_true=np.concatenate((y_train, y_dev), axis=None)\n",
    "print (X_concat.shape, y_concat.shape, y_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data\n",
      "Data saved!\n"
     ]
    }
   ],
   "source": [
    "print (\"Saving data\")\n",
    "np.save('data/X_concat.npy', X_concat)\n",
    "np.save('data/y_concat.npy', y_concat)\n",
    "np.save('data/y_true.npy',y_true)\n",
    "print (\"Data saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stem_tokenize(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    return [stemmer.stem(w) for w in word_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vect = TfidfVectorizer(analyzer= 'word', tokenizer=Stem_tokenize,\n",
    "                                stop_words=stopwords.words('english') + list(string.punctuation),\n",
    "                                lowercase=True, strip_accents='ascii', ngram_range=(1,2),\n",
    "                                min_df=5, max_df= 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train=Vect.fit_transform(X_concat)\n",
    "classifier_NB = MultinomialNB(alpha=0.01)\n",
    "classifier_NB.fit(data_train[:len(X_train)], y_true[:len(y_train)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self-learning NB. score 0.8610374165218186\n"
     ]
    }
   ],
   "source": [
    "print (\"self-learning NB. score\", classifier_NB.score(data_train[len(X_train):], y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model/NB1_Vect.pkl', 'wb') as fid:\n",
    "    pickle.dump(classifier_NB, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15076L, 100553L)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transform =Vect.fit_transform(X_concat)\n",
    "X=X_transform.toarray()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/X_vect.npy',X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.625\n",
    "ssmodel = SelfLearningModel(classifier_NB)\n",
    "ssmodel.fit(X, y_concat)\n",
    "print (\"Self-learning NB. score\", ssmodel.score(X, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self-learning NB. score 0.847572300344919\n"
     ]
    }
   ],
   "source": [
    "ssmodel = SelfLearningModel(classifier_NB)\n",
    "ssmodel.fit(X, y_concat)\n",
    "print (\"Self-learning NB. score\", ssmodel.score(X, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train=Vect.fit_transform(X_concat)\n",
    "classifier_NB = MultinomialNB(alpha=0.01)\n",
    "classifier_NB.fit(data_train[:len(X_train)], y_true[:len(y_train)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self-learning NB. score 0.8900821225521163\n"
     ]
    }
   ],
   "source": [
    "print (\"self-learning NB. score\", classifier_NB.score(data_train[len(X_train):], y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-4b6a048a5bba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mssmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSelfLearningModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier_NB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mssmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_concat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Self-learning NB. score\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mssmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\amanur\\Desktop\\CSC591_ML-master\\Project\\Project3\\code\\frameworks.ipynb\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;34m\"        i = 0\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m     \u001b[1;34m\"        while (len(unlabeledy_old) == 0 or numpy.any(unlabeledy!=unlabeledy_old)) and i < self.max_iter:\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m     \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[1;34m\"            unlabeledy_old = numpy.copy(unlabeledy)\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python27\\lib\\site-packages\\numpy\\core\\shape_base.pyc\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \"\"\"\n\u001b[0;32m    282\u001b[0m     \u001b[0m_warn_for_nonsequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ssmodel = SelfLearningModel(classifier_NB)\n",
    "ssmodel.fit(X, y_concat)\n",
    "print (\"Self-learning NB. score\", ssmodel.score(X, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
