{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn import metrics\n",
    "import pickle\n",
    "from nltk import word_tokenize\n",
    "from sklearn import linear_model, neural_network\n",
    "from sklearn.svm import SVC\n",
    "import timeit\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import nbimporter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from frameworks import SelfLearningModel, SKTSVM\n",
    "from methods import evaluate_and_plot\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 20 newsgroups dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18846"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove metadata \n",
    "remove = ('headers', 'footers', 'quotes') \n",
    "RANDOM_STATE = 10\n",
    "\n",
    "# Load dataset\n",
    "print(\"Loading 20 newsgroups dataset\")\n",
    "newsdata = fetch_20newsgroups(subset='all')\n",
    "len(newsdata.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 4830  5487  1131 ...  6543 10054  9924] TEST: [ 2647  7876  4857 ... 13387  2034  8962]\n",
      "Data loaded\n",
      "\n",
      "Training data documents: 5653\n",
      "Development data documents: 9423\n",
      "Test data documents: 3770\n",
      "\n",
      "Total Newsgroups : ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "X_remaining, X_test, Y_remaining, Y_test = train_test_split(newsdata.data, newsdata.target, test_size=0.20, random_state=RANDOM_STATE)\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size= 0.625,random_state=RANDOM_STATE)\n",
    "X_remaining=np.array(X_remaining)\n",
    "Y_remaining=np.array(Y_remaining)\n",
    "for train_index, test_index in sss.split(X_remaining,Y_remaining):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_dev = X_remaining[train_index], X_remaining[test_index]\n",
    "    y_train, y_dev = Y_remaining[train_index], Y_remaining[test_index]\n",
    "    \n",
    "print('Data loaded')\n",
    "print()\n",
    "print('Training data documents:', len(X_train))\n",
    "print('Development data documents:', len(X_dev))\n",
    "print('Test data documents:', len(X_test))\n",
    "print()\n",
    "print('Total Newsgroups :', newsdata.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data\n",
      "Data saved!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (\"Saving data\")\n",
    "np.save('data/train_data.npy', X_train)\n",
    "np.save('data/dev_data.npy', X_dev)\n",
    "np.save('data/test_data.npy', X_test)\n",
    "\n",
    "np.save('data/train_label.npy', y_train)\n",
    "np.save('data/dev_label.npy', y_dev)\n",
    "np.save('data/test_label.npy', Y_test)\n",
    "\n",
    "print (\"Data saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15076L,) (15076L,) (15076L,)\n"
     ]
    }
   ],
   "source": [
    "y_minus=np.full(len(y_dev), -1, dtype=int)\n",
    "\n",
    "X_concat=np.concatenate((X_train, X_dev), axis=None)\n",
    "y_concat=np.concatenate((y_train, y_minus), axis=None)\n",
    "y_true=np.concatenate((y_train, y_dev), axis=None)\n",
    "print (X_concat.shape, y_concat.shape, y_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data\n",
      "Data saved!\n"
     ]
    }
   ],
   "source": [
    "print (\"Saving data\")\n",
    "np.save('data/X_concat.npy', X_concat)\n",
    "np.save('data/y_concat.npy', y_concat)\n",
    "np.save('data/y_true.npy',y_true)\n",
    "print (\"Data saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stem_tokenize(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    return [stemmer.stem(w) for w in word_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vect = TfidfVectorizer(analyzer= 'word', tokenizer=Stem_tokenize,\n",
    "                                stop_words=stopwords.words('english') + list(string.punctuation),\n",
    "                                lowercase=True, strip_accents='ascii', ngram_range=(1,2),\n",
    "                                min_df=5, max_df= 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train=Vect.fit_transform(X_concat)\n",
    "classifier_NB = MultinomialNB(alpha=0.01)\n",
    "classifier_NB.fit(data_train[:len(X_train)], y_true[:len(y_train)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self-learning NB. score 0.8805051469807916\n"
     ]
    }
   ],
   "source": [
    "print (\"self-learning NB. score\", classifier_NB.score(data_train[len(X_train):], y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supervised RF score 0.7107078425130001\n"
     ]
    }
   ],
   "source": [
    "basemodel =  KNeighborsClassifier(n_neighbors=4)\n",
    "basemodel.fit(data_train[:len(X_train)], y_true[:len(y_train)])\n",
    "print (\"supervised RF score\", basemodel.score(data_train[len(X_train):], y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supervised NN. score 0.5957762920513637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python27\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "basemodel_NN = neural_network.MLPClassifier(hidden_layer_sizes=3) \n",
    "basemodel_NN.fit(data_train[:len(X_train)], y_true[:len(y_train)])\n",
    "print (\"supervised NN. score\", basemodel_NN.score(data_train[len(X_train):], y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supervised SVM. score 0.8867664225830415\n"
     ]
    }
   ],
   "source": [
    "SVM = linear_model.SGDClassifier(loss='hinge') \n",
    "SVM.fit(data_train[:len(X_train)], y_true[:len(y_train)])\n",
    "print (\"supervised SVM. score\", SVM.score(data_train[len(X_train):], y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model/NB1_Vect.pkl', 'wb') as fid:\n",
    "    pickle.dump(classifier_NB, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15076L, 100553L)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transform =Vect.fit_transform(X_concat)\n",
    "X=X_transform.toarray()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/X_vect.npy',X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self-learning NB. score 0.9148315202971611\n"
     ]
    }
   ],
   "source": [
    "ssmodel = SelfLearningModel(classifier_NB)\n",
    "ssmodel.fit(X, y_concat)\n",
    "print (\"Self-learning NB. score\", ssmodel.score(X, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmmodel = SelfLearningModel(basemodel)\n",
    "svmmodel.fit(X, y_concat)\n",
    "print (\"Self-learning NB - SVM score\", svmmodel.score(X, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = linear_model.SGDClassifier(loss='log') \n",
    "SVM.fit(data_train[:len(X_train)], y_true[:len(y_train)])\n",
    "print (\"supervised SVM. score\", SVM.score(data_train[len(X_train):], y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdmodel = SelfLearningModel(SVM)\n",
    "sgdmodel.fit(X, y_concat)\n",
    "print (\"Self-learning NB - SVM score\", sgdmodel.score(X, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
